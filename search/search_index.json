{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Isaac SIM Jetson HIL Course Doc","text":"<p>This site hosts documents and references that accompany the following hands-on courses.</p>"},{"location":"index.html#course-slide","title":"Course slide","text":""},{"location":"index.html#hands-on-session-breakdown","title":"Hands-on session breakdown","text":""},{"location":"index.html#when-this-course-is-offered","title":"When this course is offered","text":"<ul> <li>GTC 2024 - [DLIT61534] Elevate Your Robotics Game: Unleash High Performance with Isaac ROS &amp; Isaac SIM</li> </ul>"},{"location":"faq.html","title":"FAQ","text":""},{"location":"faq.html#high-level-questions","title":"High-level questions","text":""},{"location":"faq.html#what-is-the-requirement-to-run-isaac-sim","title":"What is the requirement to run Isaac Sim?","text":""},{"location":"faq.html#what-is-the-requirement-to-run-isaac-ros","title":"What is the requirement to run Isaac ROS?","text":""},{"location":"faq.html#can-jetson-run-isaac-sim","title":"Can Jetson run Isaac SIM?","text":"<p>Short answer: No.</p>"},{"location":"faq.html#can-i-run-isaac-sim-on-my-windows-pc","title":"Can I run Isaac SIM on my Windows PC?","text":"<p>Yes, you can run Isaac Sim on your Windows PC. To begin downloading Isaac Sim, the first step is to download Omniverse on your system. When doing so, ensure to select the Windows version as depicted in the image below:</p> <p></p>"},{"location":"faq.html#can-i-re-run-this-lab-with-windows-pc-to-run-isaac-sim","title":"Can I (re-)run this lab with Windows PC to run Isaac SIM?","text":"<p>Yes, you can replicate the same instructions on your Windows machine, and you should achieve identical results.</p>"},{"location":"faq.html#what-is-the-minimum-system-requirement-for-running-isaac-sim","title":"What is the minimum system requirement for running Isaac SIM?","text":"<p>answer answer</p>"},{"location":"faq.html#what-are-the-performance-numbers-running-isaac-ros-packages","title":"What are the performance numbers running Isaac ROS packages?","text":"<p>Performance Summary \u2014 isaac_ros_docs documentation</p>"},{"location":"faq.html#whats-the-best-way-to-post-questions","title":"What\u2019s the best way to post questions?","text":"<ol> <li>Isaac ROS Developer forum</li> <li>GitHub issues for each Repo</li> </ol>"},{"location":"faq.html#can-isaac-ros-run-on-jetson-orin-nano","title":"Can Isaac ROS run on Jetson Orin Nano?","text":"<p>Yes, it can. However, your performance may vary compared to that of Jetson AGX Orin.</p>"},{"location":"faq.html#technical-questions","title":"Technical questions","text":""},{"location":"faq.html#how-can-i-accelerate-my-standard-ros-2-node-using-isaac-ros","title":"How can I accelerate my standard ROS 2 node using Isaac ROS?","text":"<ol> <li>NITROS</li> <li>Yolov8 sample</li> </ol>"},{"location":"faq.html#how-do-i-integrate-nvblox-into-my-nav-stack","title":"How do I integrate Nvblox into my NAV stack?","text":"<p>As a local costmap provider. See nvblox_nav2_costmap_provider</p>"},{"location":"faq.html#what-the-difference-between-cuvslam-vs-nvblox","title":"What the difference between cuVSLAM vs Nvblox?","text":"<p>cuVSLAM is a visual odometry/visual SLAM tool designed for localization purposes. It works in tandem with Nvblox, which constructs a 3D representation of the environment and utilizes cuVSLAM to determine its position. Moreover, Nvblox facilitates obstacle mapping. cuVSLAM, on the other hand, constructs an internal localization map.</p>"},{"location":"faq.html#how-do-i-render-an-nvblox-generated-3d-mesh-on-foxglove","title":"How do I render an Nvblox-generated 3D mesh on Foxglove?","text":"<p>Foxglove Nvblox plugin.</p>"},{"location":"faq.html#does-nvblox-generate-the-global-andor-local-costmap","title":"Does Nvblox generate the global and/or local costmap?","text":"<p>Local costmap. It can theoretically be used to create a global costmap but that would be memory intensive to create a ESDF/voxel map and then extract a 2D costmap from it.</p>"},{"location":"faq.html#is-there-a-planer-constraint-for-the-nvblox","title":"Is there a planer constraint for the Nvblox?","text":"<p>No.</p>"},{"location":"faq.html#what-are-the-parameters-for-nvblox","title":"What are the parameters for Nvblox?","text":"<p>Nvblox parameters here.</p>"},{"location":"faq.html#biggest-area-that-nvblox-can-map","title":"Biggest area that Nvblox can map?","text":"<p>Memory consumption is the primary limiting factor. For 2D ESDF output (such as ground robot navigation), the dominant memory consumer is the 3D TSDF, which requires 2 bytes per voxel. At a voxel size of 5cm, this amounts to 64Kb per cubic meter. While the Orin can support up to 64Gb of memory, it's advisable not to allocate all of it to the map. Assuming 16Gb for the map, this translates to around 250,000 cubic meters, covering approximately 80,000 square meters of floor area with 3-meter-high ceilings, roughly equivalent to a small warehouse. However, this analysis disregards memory allocation only within observed space, likely doubling the estimated figure. Currently, nvblox is primarily intended for local mapping. In an upcoming release, default settings will include voxel decay and map cropping beyond the robot's vicinity to restrict map growth.</p>"},{"location":"faq.html#how-often-does-the-nvblox-mesh-get-refreshed","title":"How often does the Nvblox mesh get refreshed?","text":"<p>It depends on the configurable parameter known as the window batch size.</p>"},{"location":"faq.html#can-i-add-a-sensor-on-an-existing-robot-in-isaac-sim","title":"Can I add a sensor on an existing robot in Isaac SIM?","text":"<p>Yes, here are the instructions</p>"},{"location":"hardware-in-loop.html","title":"Hardware-in-Loop setup","text":"<p>Isaac Sim can be used to run and test the ROS2 applications. There are two ways we can configure the system.</p> <ul> <li>Software in the Loop</li> <li>Hardware in the Loop</li> </ul> <p>Software in the Loop (SIL) refers to a configuration where the software being tested is not running on the target hardware platform. For example, Isaac ROS packages being tested on x86 before deployment on a Jetson device is SIL.</p> <p>Hardware in the Loop (HIL) refers to a configuration where the software is being tested on the target hardware platform. For example, Isaac ROS packages being tested on a Jetson device before deployment is HIL.</p>"},{"location":"hardware-in-loop.html#exercise-1-verify-the-basic-communication","title":"Exercise 1. Verify the basic communication","text":"<p>We will use ROS 2 to communicate robot information between Jetson and PC.</p> <p>Info</p> <p>For optimal and reliable data communication between Jetson and PC, it is generally ideal to use a wired Ethernet to foam a robust network connection, especially on a moving platform like a robot.</p> <p>However for the ease of setup in this lab, Jetson and PC are connected via a USB (Type-A end on PC and USB-C end on Jetson) cable, to form a peer-to-peer, local closed network.</p> <p>Jetson, when connected as a device, presents a USB communication device class (CDC) among other classes, effectively forming an \"Ethernet over USB\" connection between the Jetson and the host PC.</p> <p>Jetson assigns the IP address <code>192.168.55.1</code> to itself and assign <code>192.168.55.100</code> to the host side device, so conveniently Jetson is always reachable by the IP address from the host.</p> <p></p> <p>This closed network also helps to accommodate multiple ROS 2 systems in a same room, eliminating the needs of setting different <code>ROS_DOMAIN_ID</code>.</p> <p>Let's check the IP address on both Jetson and PC to first verify that they can ping each other. </p> <ol> <li> <p>Ensure that both the Jetson and PC are connected on the same network. </p> <p>Info</p> <p>In the case of our lab, they are foaming a peer-to-peer style local network over the USB Type-A to USB-C cable.</p> </li> <li> <p>Check the IP address of each device by using <code>ip addr</code> command on both Jetson and PC, and test if it can reach each other by using <code>ping</code> command.</p> <pre><code>ip addr\nping &lt;other_device_ip&gt;\n</code></pre> </li> </ol>"},{"location":"hardware-in-loop.html#exercise-2-verify-the-ros-2-communication","title":"Exercise 2. Verify the ROS 2 communication","text":""},{"location":"hardware-in-loop.html#on-pc-start-simulation","title":"On PC, start simulation","text":"<ol> <li> <p>Open the following file path in Isaac Sim</p> <pre><code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/Simple_Warehouse/course_env_5.usd\n</code></pre> <p>or navigate to the environment you have created so far in Isaac Sim.</p> </li> <li> <p>Initiate the simulation in Isaac Sim by clicking the \"Play\" button, activating both the graph and the physics engine.</p> </li> </ol>"},{"location":"hardware-in-loop.html#on-jetson-remotely-teleop-the-robot-in-isaac-sim","title":"On Jetson, remotely teleop the robot in Isaac Sim","text":"<ol> <li> <p>Launch the Isaac ROS dev container suing the <code>run_dev.sh</code> script:</p> <pre><code>cd ${ISAAC_ROS_WS}/src/isaac_ros_common &amp;&amp; \\\n./scripts/run_dev.sh ${ISAAC_ROS_WS} \n</code></pre> </li> <li> <p>Once in the container, source the workspace</p> <pre><code>source /workspaces/isaac_ros-dev/install/setup.bash\n</code></pre> </li> <li> <p>In the ROS-sourced terminal, check that the associated ROS topics exist.</p> <pre><code>ros2 topic list\n</code></pre> </li> <li> <p>Send a twist message to cmd_vel topic</p> <pre><code>ros2 topic pub /cmd_vel geometry_msgs/Twist '{linear:  {x: 0.2, y: 0.0, z: 0.0}, angular: {x: 0.0,y: 0.0,z: 0.0}}'\n</code></pre> <p>Note</p> <p>You can also use <code>teleop_twist_keyboard</code> package to control the robot</p> </li> </ol>"},{"location":"hardware-in-loop.html#exercise-3-run-hil-isaac-sim-nvblox","title":"Exercise 3. Run HIL - Isaac Sim + Nvblox","text":"<p>Isaac ROS Nvblox provides ROS 2 packages for 3D reconstruction and navigation cost maps. It processes depth and pose data to create real-time 3D scene reconstructions and generates 2D costmaps for navigation, aiding in obstacle avoidance.</p> <p>Compatible with depth cameras and/or 3D LiDAR, it utilizes GPU acceleration for efficient computation, leveraging the nvblox C++ library for reconstruction and costmap generation.</p> <p>In a typical graph, <code>isaac_ros_nvblox</code> takes depth and color images along with pose data, computes a 3D scene reconstruction on the GPU, and generates an output cost map for navigation. Colorized 3D reconstruction updates can be visualized in RViz in real-time as well.</p> <p>Cheat-file</p> <p>You can access a pre-populated environment at <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/Simple_Warehouse/course_env_6.usd</code></p>"},{"location":"hardware-in-loop.html#modify-the-robots-action-graph","title":"Modify the robot's Action Graph","text":""},{"location":"hardware-in-loop.html#drive-action-graph","title":"Drive Action Graph","text":"<ol> <li> <p>Right click on the <code>drive_actiongraph</code> and open the Graph</p> <p></p> </li> <li> <p>Search the relevant Nodes in the search bar and build the graph shown below just below the Drive action graph.</p> <p>Connect the Exec In for each node to the On Playback Tick Node (which you may have created earlier when setting up the drive action graph) for all nodes not shown in this image.</p> <p></p> </li> <li> <p>Set the node properties</p> <ol> <li> <p>Assign the chassisPrim to the base link of the robot to get the odometry reading using the Isaac Compute Odometry Node.</p> <p> </p> </li> <li> <p>[Optional] If your chassisprim is different from base_link then update the chassisFramId in the ROS2 Publish Odometry Node. In our example we do not need to change it.</p> <p></p> </li> <li> <p>[Optional] If your chassisprim is different from base_link then update the ChildFramId in the ROS2 Publish Raw Transform Tree Node. In our example we do not need to change it.</p> <p></p> </li> <li> <p>Publish the base_link transform by selecting base_link as both parentPrim and targetPrim in the ROS2 Publish Transform Tree Node. How to assign a prim has already been shown in Step 3a above.</p> <p></p> </li> <li> <p>Publish the base_link transform to both cameras by selecting base_link as parentPrim and <code>Camera_OmniVision_OV9782_Left</code> and <code>Camera_OmniVision_OV9782_Right</code> as targetPrims in the other ROS2 Publish Transform Tree Node. How to assign a prim has already been shown in the step above.</p> <p></p> </li> </ol> </li> </ol>"},{"location":"hardware-in-loop.html#graph-explanation","title":"Graph Explanation","text":"<ul> <li>On Playback Tick Node: Generates a tick during simulation playback, ensuring nodes execute their functions every simulation step.</li> <li>Isaac Compute Odometry Node: Holds values related to odometry</li> <li>ROS2 Publish Raw Transform Tree: This node publishes a user-defined transformation between any two coordinate frames as a ROS2 Transform Tree</li> <li>ROS2 Publish Transform Tree: This node publishes the pose of prims as a ROS2 Transform Tree</li> <li>ROS2 Publish Odometry: This node publishes odometry as a ROS2 Odometry message</li> <li>ROS2 Publish Clock: This node publishes the given time as a ROS2 Clock message</li> <li>Isaac Read Sim Time: Holds values related to system timestamps</li> </ul>"},{"location":"hardware-in-loop.html#camera-publisher-action-graph","title":"Camera Publisher Action Graph","text":"<ol> <li> <p>Right click on the camera_publisher action graph and select \"Open Graph\"</p> <p></p> </li> <li> <p>Search the relevant Nodes in the search bar and build the graph shown below just below the original camera publisher graph.</p> <p>We just need to add two more ROS2 Camera Helper nodes to publish the depth image from the camera.</p> <p></p> </li> <li> <p>Set the node properties</p> <ol> <li> <p>Set the topicName and data type for the new ROS2 Camera Helper Nodes</p> node 1node 2 <p>topicName : <code>/front/stereo_camera/left/depth</code> type : <code>depth</code></p> <p></p> <p>topicName : <code>/front/stereo_camera/right/depth</code> type : <code>depth</code></p> <p></p> </li> <li> <p>Enable \"Reset Time on Stop\" for all the 6 ROS2 Camera Helper Nodes</p> <p></p> </li> </ol> </li> <li> <p>After making the specified modifications to the graphs, click the \"Play\" button to start the simulation.</p> </li> </ol>"},{"location":"hardware-in-loop.html#graph-explanation_1","title":"Graph Explanation","text":"<ul> <li>ROS2 Camera Helper: This node handles automation of the camera sensor pipeline</li> </ul>"},{"location":"hardware-in-loop.html#launch-nvblox-on-jetson","title":"Launch Nvblox on Jetson","text":"<p> Isaac ROS Official Documentation - Isaac ROS Nvblox</p> <ol> <li> <p>Ensure that you have established a ROS 2 workspace for experimenting with Isaac ROS, and set the <code>ISAAC_ROS_WS</code> environmental variable to point to your ROS 2 workspace directory, following the initial setup instructions for Isaac ROS previously mentioned - Link</p> </li> <li> <p>Launch the Docker container using the run_dev.sh script:</p> <pre><code>cd ${ISAAC_ROS_WS}/src/isaac_ros_common &amp;&amp; \\\n./scripts/run_dev.sh ${ISAAC_ROS_WS}\n</code></pre> </li> <li> <p>Once inside the container, source the workspace:</p> <pre><code>source /workspaces/isaac_ros-dev/install/setup.bash\n</code></pre> </li> <li> <p>Launch the pre-composed graph launch file:</p> <pre><code>ros2 launch nvblox_examples_bringup isaac_sim_example.launch.py\n</code></pre> <p>This command will open an RViz window for visualizing the output.</p> <p></p> </li> <li> <p>Click the \"2D Goal Pose\" button in RViz and set a goal location and heading for your robot. You'll observe the mesh, costmap, and the robot navigating towards the goal.</p> <p></p> </li> </ol> <p>Tip</p> <p>If you see the robot moving very slowly then try to play with the maxLinearSpeed in Speed Differential Controller Node</p> <p></p> <p>Next</p>"},{"location":"isaac-ros.html","title":"Hands-on Session on Isaac ROS","text":""},{"location":"isaac-ros.html#about-isaac-ros","title":"About Isaac ROS","text":"<p> Official Isaac ROS Documentation - Getting Started</p> <p>NVIDIA has developed the Isaac ROS suite to harness hardware acceleration on NVIDIA Jetson and discrete GPUs, enhancing standard robotics applications. It maintains standard ROS interfaces for input and output, facilitating seamless integration and user-friendliness as a direct replacement for traditional CPU-based ROS frameworks familiar to robotics developers.</p>"},{"location":"isaac-ros.html#system-requirements","title":"System Requirements","text":"Platform Hardware Software Jetson Jetson OrinJetson Xavier JetPack 5.1.2 x86_64 NVIDIA GPU Ubuntu 20.04+CUDA 11.8+ <p>All Isaac ROS packages are tested to be compatible with ROS 2 Humble. If your application is built with ROS 1, you can integrate it with Isaac ROS using the NITROS Bridge.</p>"},{"location":"isaac-ros.html#lab-setup","title":"Lab setup","text":"<p>Info</p> <p>The following exercise assumes that the Jetson is set up by roughly following the Isaac ROS's setup procedures below.</p> <ul> <li>Hardware Setup / Computer Setup / Jetson Platforms<ul> <li>Developer Environment Setup for Jetson (NVMe installation)</li> </ul> </li> <li>Developer Environment Setup</li> </ul> <p>For the detail on how the GTC lab provided Jetson units are configured, please check this Jetson setup page.</p>"},{"location":"isaac-ros.html#exercise-1-run-isaac-ros-dev-container","title":"Exercise 1. Run Isaac ROS dev container","text":"<p> Official Isaac ROS Documentation - Isaac ROS Common</p> <p>We strongly recommend setting up your developer environment using Isaac ROS Dev Docker images to streamline your development setup with the correct versions of dependencies on both Jetson and x86_64 platforms. All tutorials have been designed with these docker images as a prerequisite.</p> <p>Before you begin, verify that your device has sufficient storage available. We recommend at least 30 GB, which likely necessitates an SSD if running on Jetson platforms.</p> <p>Note</p> <p>For this exercise you will need two terminals open on the jetson and you can arrange them in the following manner</p> <p></p> <ol> <li> <p>[  Terminal 1 ] Start the Isaac ROS dev container by executing the following command</p> <p><pre><code>echo $ISAAC_ROS_WS\n</code></pre> <pre><code>cd ${ISAAC_ROS_WS}/src/isaac_ros_common &amp;&amp; \\\n./scripts/run_dev.sh ${ISAAC_ROS_WS}\n</code></pre></p> </li> </ol> <ol> <li> <p>[  Terminal 1 ] Once in the Isaac ROS dev container, source the workspace:</p> <pre><code>source /workspaces/isaac_ros-dev/install/setup.bash\n</code></pre> </li> <li> <p>[  Terminal 2 ] When you need the 2nd terminal attached to the container, run this command again:</p> <pre><code>cd ${ISAAC_ROS_WS}/src/isaac_ros_common &amp;&amp; \\\n./scripts/run_dev.sh ${ISAAC_ROS_WS}\n</code></pre> </li> <li> <p>[  Terminal 2 ] Once in the Isaac ROS dev container, again source the workspace:</p> <pre><code>source /workspaces/isaac_ros-dev/install/setup.bash\n</code></pre> </li> </ol>"},{"location":"isaac-ros.html#exercise-2-run-isaac-ros-nvblox-with-rosbag","title":"Exercise 2. Run Isaac ROS Nvblox with Rosbag","text":"<p> Official Isaac ROS Documentation - Isaac ROS Nvblox</p>"},{"location":"isaac-ros.html#about-nvblox","title":"About Nvblox","text":"<p>Isaac ROS Nvblox contains ROS 2 packages for 3D reconstruction and cost maps for navigation. The Nvblox node processes depth and pose to reconstruct a 3D scene in real-time. It also outputs a 2D costmap for Nav2.</p> <p></p> <p>Note</p> <p>In this exercise, we will continue using the Terminal 1 and Terminal 2 set up in the above Exercise 1. If you have not completed the exercise, follow the Exercise 1 to have them ready. </p> <ol> <li> <p>[  Terminal 1 ]  Run the launch file for Nvblox with <code>nav2</code></p> <pre><code>ros2 launch nvblox_examples_bringup isaac_sim_example.launch.py\n</code></pre> </li> <li> <p>[  Terminal 2 ] Playback the recorded rosbag</p> <p>Play the recorded rosbag file.</p> <pre><code>ros2 bag play src/isaac_ros_nvblox/nvblox_ros/test/test_cases/rosbags/nvblox_pol\n</code></pre> <p>RViz should start showing visualization like the following.</p> <p></p> </li> </ol> <p>Next</p>"},{"location":"nextgen-ai.html","title":"Next-gen AI Integration","text":""},{"location":"nextgen-ai.html#ros2-nanoowl","title":"ROS2 NanoOWL","text":""},{"location":"nextgen-ai.html#owl-vit","title":"OWL-ViT","text":"<p>OWL-ViT (Vision Transformer for Open-World Localization) is an open-vocabulary object detection network trained on (image, text) pairs. It is used to query an image with text queries to detect target objects described in text. Learn more about OWL-ViT - Link</p>"},{"location":"nextgen-ai.html#nanoowl","title":"NanoOWL","text":"<p>NanoOWL is a project that optimizes OWL-ViT for real-time inference on Jetson Orin platforms with NVIDIA TensorRT. Visit the NanoOWL project for more information.</p> <p></p> <p>ROS2-NanoOWL is a ROS 2 node for open-vocabulary object detection using NanoOWL. We will be running this ros2_nanoowl node on the Jetson from our Isaac ROS development environment. It will detect objects in Isaac Sim based on text queries that we will provide from Foxglove. </p>"},{"location":"nextgen-ai.html#setup","title":"Setup","text":"<p>Detailed setup instructions - Link.</p> <p>By this point in the session, we have already set up the Isaac ROS development environment. We\u2019ll be using the same setup for running ROS2-NanoOWL. Some additional packages are required, which we have already made available in your ROS workspace:</p> <ul> <li>ROS2-NanoOWL</li> <li>nanoowl</li> <li>torch2trt</li> <li>torchvision</li> <li>tensorrt</li> <li>transformers</li> <li>demos (for cam2image)</li> </ul> <p>We need the TensorRT engine for the OWL-ViT vision encoder. This step takes a few minutes and needs to be done on the target hardware (Jetson in our case). We\u2019ve made this engine file available already in the data folder under ROS2-NanoOWL.</p>"},{"location":"nextgen-ai.html#running-with-webcam","title":"Running with webcam","text":"<p>Let\u2019s put the webcam to some use and try detecting objects around us! </p> <p>[  Terminal 1 ] Launch the ros2_nanoowl node: <pre><code>ros2 launch ros2_nanoowl camera_input_example.launch.py thresholds:=0.1 image_encoder_engine:='src/ROS2-NanoOWL/data/owl_image_encoder_patch32.engine'\n</code></pre> Specify the desired detection threshold (in the thresholds parameter) and the path to your encoder engine (in the image_encoder_engine parameter).</p> <p>[  Terminal 2 ] Open a new terminal and run the container: <pre><code>cd ${ISAAC_ROS_WS}/src/isaac_ros_common &amp;&amp; \\\n./scripts/run_dev.sh ${ISAAC_ROS_WS}\n</code></pre> Once in the Isaac ROS dev container, again source the workspace:</p> <p><pre><code>source /workspaces/isaac_ros-dev/install/setup.bash\n</code></pre> Publish your input query: <pre><code>ros2 topic pub /input_query std_msgs/String 'data: a person, a box, a forklift'\n</code></pre></p> <p>[  Terminal 3 ] Open a new terminal and run the RViz: <pre><code>rviz2\n</code></pre></p>"},{"location":"nextgen-ai.html#running-with-isaac-sim","title":"Running with Isaac Sim","text":"<p>Check that images from Isaac Sim are being published on topic /front/stereo_camera/left/rgb using the command below. We\u2019ll perform detection on these images: <pre><code>ros2 topic echo /front/stereo_camera/left/rgb\n</code></pre></p> <p>Launch the ros2_nanoowl node: <pre><code>ros2 launch ros2_nanoowl nano_owl_example.launch.py thresholds:=0.1 image_encoder_engine:='src/ROS2-NanoOWL/data/owl_image_encoder_patch32.engine'\n</code></pre></p> <p>Specify the desired detection threshold (in the thresholds parameter) and the path to your encoder engine (in the image_encoder_engine parameter).</p> <p>Publish a query from the Foxglove publish panel (Foxglove setup instructions here). Remember to click the Publish button everytime you update your query! Observe output detections on topic /output_image. </p> <p></p> <p>Info</p> <p>A modification has been made to the launch file from the ROS2-NanoOWL GitHub for this session. The input image name has been remapped so that the ros2_nanoowl node subscribes to images from Isaac Sim on topic /front/stereo_camera/left/rgb instead of /input_image. This change is on line 45 of nano_owl_example.launch.py:</p> <ul> <li>remappings=[('input_image', '/front/stereo_camera/left/rgb')]</li> </ul>"},{"location":"references.html","title":"References","text":"<ul> <li>NVIDIA Technical Blog : Design Your Robot on Hardware-in-the-Loop with NVIDIA Jetson</li> </ul>"},{"location":"setup_jetson.html","title":"Jetson Setup","text":"<p>This page documents how the Jetson used in the lab was set up prior to the course by instructors.</p> <p>People can reference this page to learn how their own Jetson can be set up in order to follow the contents of this course by their own.</p>"},{"location":"setup_jetson.html#jetson-hardware","title":"Jetson hardware","text":"<p>For our course at the GTC 24, Jetson AGX Orin 64GB Developer Kit was used, partially because of the requirement of other courses that share the same lab room. One could use other Orin generation Jetson, such as Jetson Orin Nano Developer Kit, however it has not been fully verified.</p> <p>For learning what Jetson developer kits are available and the order information, please check the Jetson Developer Kits page on NVIDIA.com.</p>"},{"location":"setup_jetson.html#install-jetpack-512","title":"Install JetPack 5.1.2","text":"<p>For this hands-on course, we run Isaac ROS 2.1 (the most up-to-date at the time of GTC 24) on Jetson, which requires JetPack 5.1.2.</p> <p>Jetson AGX Orin 64GB Developer Kit shall be flashed using a host Linux PC, following the steps below.</p> <pre><code>cd\nmkdir L4T_r35.4.1\ncd L4T_r35.4.1\nwget https://developer.nvidia.com/downloads/embedded/l4t/r35_release_v4.1/release/jetson_linux_r35.4.1_aarch64.tbz2\nwget https://developer.nvidia.com/downloads/embedded/l4t/r35_release_v4.1/release/tegra_linux_sample-root-filesystem_r35.4.1_aarch64.tbz2\ntar xf jetson_linux_r35.4.1_aarch64.tbz2\nsudo tar xpf tegra_linux_sample-root-filesystem_r35.4.1_aarch64.tbz2 -C Linux_for_Tegra/rootfs/\ncd Linux_for_Tegra/\nsudo ./apply_binaries.sh\nsudo ./tools/l4t_flash_prerequisites.sh\nsudo ./flash.sh jetson-agx-orin-devkit internal\n</code></pre> <p>Special \"Dual boot\" setup</p> Re-flashing QSPI to switch between JP5  JP6"},{"location":"setup_jetson.html#special-case-dual-boot-with-jetpack-60-dp","title":"Special case: Dual-boot with JetPack 6.0 DP","text":"<p>Depending on the event's / other labs' needs, you may need to have another version of JetPack on the different storage medium on Jetson, in order to realize a \"dual-boot\" setup.</p> <p>We explain the additional instructions for such special setup using a folded adomonition like following.</p> Installing JetPack 6.0 DP on NVMe <p>After installing JetPack 5.1.2 on eMMC, you can perform the following to install JetPack 6.0 DP on NVMe.</p> <pre><code>cd ~/L4T_r36.2/Linux_for_Tegra\nsudo ./nvsdkmanager_flash.sh --storage nvme0n1p1\n</code></pre> <p>This will re-write the contents on QSPI bootloader, so Jetson is configure to boot into JetPack 6.0 DP from NVMe, although the eMMC is left in tact with the JetPack 5.1.2 contents.</p> <p>Populating the <code>~/L4T_r36.2/Linux_for_Tegra</code> directory process is like following.</p> <pre><code>cd\nmkdir L4T_r36.2\ncd L4T_r36.2\nwget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v2.0/release/jetson_linux_r36.2.0_aarch64.tbz2\nwget https://developer.nvidia.com/downloads/embedded/l4t/r36_release_v2.0/release/tegra_linux_sample-root-filesystem_r36.2.0_aarch64.tbz2\ntar xf jetson_linux_r36.2.0_aarch64.tbz2\nsudo tar xpf tegra_linux_sample-root-filesystem_r36.2.0_aarch64.tbz2 -C Linux_for_Tegra/rootfs/\ncd Linux_for_Tegra/\nsudo ./apply_binaries.sh\nsudo ./tools/l4t_flash_prerequisites.sh\n</code></pre> <p>In later section, we explain how to switch JetPack 5 (booting from eMMC) and JetPack 6 DP (booting from NVMe) by re-flashing QSPI NOR flash memory containing the bootloader and the DTB overlay, and how we can set up an additional partition on NVMe SSD for JetPack 5.</p> <p></p>"},{"location":"setup_jetson.html#switching-between-jp5-jp6","title":"Switching between JP5  JP6","text":"Switching to JP 5.1.2Switching to JP 6.0 DP <p>Once you have installed JetPack 5 on eMMC and JetPack 6 DP on NVMe, you can issue the following commands on the attached Linux PC to re-flash the QSPI to configure Jetson to boot into JetPack 5.</p> <p>First, put Jetson into Forced Recovery mode by pressing <code>Reset</code> button (next to the LED) while holding <code>Forced Recovery</code> button (middle).</p> <p>Caution</p> <p>On the PC, make sure to download <code>jetson-agx-orin-devkit-qspi.conf</code> from here and save under <code>Linux_for_Tegra</code> directory first.</p> <pre><code>cd ~/L4T_r35.4.1/Linux_for_Tegra\nsudo ADDITIONAL_DTB_OVERLAY=\"BootOrderEmmc.dtbo\" ./flash.sh jetson-agx-orin-devkit-qspi mmcblk0p1\n</code></pre> <p>Flashing process will take about 8 minutes.</p> <p>Once you have installed JetPack 5 on eMMC and JetPack 6 DP on NVMe, you can issue the following commands on the attached Linux PC to re-flash the QSPI to configure Jetson to boot into JetPack 6 DP.</p> <p>First, put Jetson into Forced Recovery mode by pressing <code>Reset</code> button (next to the LED) while holding <code>Forced Recovery</code> button (middle).</p> <pre><code>cd ~/L4T_r36.2/Linux_for_Tegra\nsudo ADDITIONAL_DTB_OVERLAY=\"BootOrderNvme.dtbo\" ./flash.sh p3737-0000-p3701-0000-qspi nvme0n1p1\n</code></pre> <p>Flashing process will take about 8 minutes.</p>"},{"location":"setup_jetson.html#ssd-setup","title":"SSD setup","text":"<p>Follow this instruction on Isaac ROS Doc to auto-mount SSD and set up Docker directory on SSD.</p> <p>Only when you have a special need to configure your Jetson to have a \"dual boot\" configuration with other version of JetPack like for the labs at GTC 24, follow the steps below.</p> Setting up an additional partition on existing NVMe"},{"location":"setup_jetson.html#in-case-nvme-already-populated-by-jetpack-60-dp","title":"In case NVMe already populated by JetPack 6.0 DP","text":""},{"location":"setup_jetson.html#gparted","title":"GParted","text":"<p>First install <code>gparted</code>.</p> <pre><code>sudo apt install -y gparted\n</code></pre> <p>Start <code>gparted</code> and select <code>/dev/nvme0n1</code></p> <p></p> <p>Select the largest partition <code>**APP**</code>, and from the context menu select \"Resize/Move\"</p> <p></p> <p>Shrink the current APP partition to create about <code>99,000 MiB</code> of free space, and hit Resize/Move button.</p> <p></p> <p>Back on the main window, press the green checkmark icon (\u2714) to start the partition resizing operation. Click \"Apply\" on the confirmation dialog.</p> <p>It takes 10-20 seconds and you will see the operation successfully completed like this.</p> <p></p> <p>Right-click on \"unallocated\" partition from the list and select \"New\" from the context menu.</p> <p></p> <p>Enter \"JP5\" or something in \"Label\" for easy identification, and click \"Add\".</p> <p></p> <p>Back on the main window, press the green checkmark icon (\u2714) to start the partition creation operation.</p> <p>Click \"Apply\" on the confirmation dialog, and the operation should be completed in a second.</p> <p></p> <p>You should see the new <code>/dev/nvme0n1p16</code> created in the list.</p> <p></p> <p>You can close <code>gparted</code> application.</p>"},{"location":"setup_jetson.html#terminal-operation","title":"Terminal operation","text":"<p>Once everything is done with GParted, open a new terminal to perform the following.</p> <pre><code>sudo mkfs.ext4 /dev/nvme0n1p16\nsudo mkdir /ssd\nsudo mount /dev/nvme0n1p16 /ssd\necho \"/dev/nvme0n1p16 /ssd/ ext4 defaults 0 2\" | sudo tee -a /etc/fstab\ncat /etc/fstab\ndf -h\n</code></pre> <p>Make sure you see <code>/dev/nvm0n1p16</code> of about 95GB mounted on <code>/ssd</code>.</p> <p>Go through the rest of the Docker directory setup on this doc.</p> <p>Remember </p>"},{"location":"setup_jetson.html#isaac-ros-setup","title":"Isaac ROS setup","text":"<p> Official Isaac ROS Documentation - Computer Setup - Jetson Platforms</p> <p>Install the whole JetPack (or only install docker and VPI?).</p> <pre><code>sudo apt update\nsudo apt install -y nvidia-jetpack\n</code></pre> <p>Rest of the setup.</p> <pre><code>cat /etc/nv_tegra_release\nsudo /usr/sbin/nvpmodel -m 0\nsudo usermod -aG docker $USER\nnewgrp docker\n\n# Add Docker's official GPG key:\nsudo apt-get update\nsudo apt-get install ca-certificates curl gnupg\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\n\n# Add the repository to Apt sources:\necho \\\n\"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n\"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\\nsudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\nsudo apt-get update\n\nsudo apt install docker-buildx-plugin\n</code></pre> <p>Isaac ROS container image pull and build.</p> <pre><code>sudo systemctl daemon-reload &amp;&amp; sudo systemctl restart docker\nsudo apt-get install git-lfs\ngit lfs install --skip-repo\nmkdir -p  /ssd/workspaces/isaac_ros-dev/src\necho \"export ISAAC_ROS_WS=/ssd/workspaces/isaac_ros-dev/\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\ncd ${ISAAC_ROS_WS}/src\nmkdir src\ngit clone https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_common.git\ncd ${ISAAC_ROS_WS}/src/isaac_ros_common\n./scripts/run_dev.sh ${ISAAC_ROS_WS}\n</code></pre>"},{"location":"setup_jetson.html#nvblox-setup","title":"Nvblox setup","text":"<p> Official Isaac ROS Documentation - <code>isaac_ros_nvblox</code> - Quickstart</p> <pre><code>cd ${ISAAC_ROS_WS}/src\ngit clone --recurse-submodules https://github.com/NVIDIA-ISAAC-ROS/isaac_ros_nvblox.git &amp;&amp; \\\n    cd isaac_ros_nvblox &amp;&amp; git lfs pull\ncd ${ISAAC_ROS_WS}/src/isaac_ros_nvblox &amp;&amp; \\\n  git lfs pull -X \"\" -I \"nvblox_ros/test/test_cases/rosbags/nvblox_pol\"\ncd ${ISAAC_ROS_WS}/src/isaac_ros_common &amp;&amp; \\\n  ./scripts/run_dev.sh ${ISAAC_ROS_WS}\n</code></pre> <p>Inside the container,</p> <pre><code>cd /workspaces/isaac_ros-dev/ &amp;&amp; \\\n    rosdep install -i -r --from-paths src --rosdistro humble -y --skip-keys \"libopencv-dev libopencv-contrib-dev libopencv-imgproc-dev python-opencv python3-opencv nvblox\"\ncd /workspaces/isaac_ros-dev &amp;&amp; \\\n  colcon build --symlink-install &amp;&amp; \\\n  source install/setup.bash\n</code></pre>"},{"location":"setup_jetson.html#docker-container-image-mod-and-swap","title":"Docker container image mod and swap","text":""},{"location":"setup_jetson.html#clone-jetpack-512","title":"Clone JetPack 5.1.2","text":""},{"location":"setup_jetson.html#capturing-the-image","title":"Capturing the image","text":"<p>First, connect the source (original) Jetson unit to the Linux PC and put Jetson into Forced Recovery mode.</p> <p>Issue the following to extract the APP partition image and save it as <code>gtc-jp5.img</code> on your PC.</p> <pre><code>sudo ./flash.sh -r -k APP -G gtc-jp5.img jetson-agx-orin-devkit mmcblk0p1\n</code></pre> <p>Attention</p> <p>In case you ended up having an empty <code>gtc-jp5.img</code> file:</p> <pre><code>$ ls -lh gtc-0311-jp5.img\n-rwxr-xr-x 1 root root 0 Mar 11 14:14 gtc-0311-jp5.img\n</code></pre> <p>Here is a work-around to convert the <code>.img.raw</code> file to <code>.img</code> file.</p> <pre><code>cp gtc-0311-jp5.img.raw system2.img.raw\nlosetup -f system2.img.raw\nlosetup\nsudo resize2fs /dev/loop16 55G\nsudo truncate system2.img.raw --size 59055800320\nsudo apt install img2simg\nsudo img2simg system2.img.raw gtc-0311-jp5.img\nls -lh gtc-0311-jp5.img\nrm system2.img.raw\n</code></pre>"},{"location":"setup_jetson.html#flashing-with-the-image","title":"Flashing with the image","text":"<p>Info</p> <p>If you are using a new PC to set for flashing, go through the follwoings.</p> <pre><code>cd\nmkdir L4T_r35.4.1\ncd L4T_r35.4.1\nwget https://developer.nvidia.com/downloads/embedded/l4t/r35_release_v4.1/release/jetson_linux_r35.4.1_aarch64.tbz2\nwget https://developer.nvidia.com/downloads/embedded/l4t/r35_release_v4.1/release/tegra_linux_sample-root-filesystem_r35.4.1_aarch64.tbz2\ntar xf jetson_linux_r35.4.1_aarch64.tbz2\nsudo tar xpf tegra_linux_sample-root-filesystem_r35.4.1_aarch64.tbz2 -C Linux_for_Tegra/rootfs/\ncd Linux_for_Tegra/\nsudo ./apply_binaries.sh\nsudo ./tools/l4t_flash_prerequisites.sh\n</code></pre> <p>And copy the following files from the PC used to capture the image.</p> <ul> <li><code>gtc-jp5.img</code></li> <li><code>bootloader/esp.img</code></li> </ul> <pre><code>scp nnnn@10.110.50.120:/home/nnnn/L4T_r35.4.1/Linux_for_Tegra/gtc-jp5.img ./\nscp nnnn@10.110.50.120:/home/nnnn/L4T_r35.4.1/Linux_for_Tegra/bootloader/esp.img ./bootloader\n</code></pre> <p>Before flashing a new unit using this image, edit <code>./bootloader/t186ref/cfg/flash_t234_qspi_sdmmc.xml</code> so that <code>APP</code> section has <code>&lt;allocation_attribute&gt;</code> to be <code>0x808</code> instead of the original <code>0x8</code>.</p> <p>The APP section should look like the following:</p> <pre><code>&lt;partition name=\"APP\" id=\"1\" type=\"data\"&gt;\n    &lt;allocation_policy&gt; sequential &lt;/allocation_policy&gt;\n    &lt;filesystem_type&gt; basic &lt;/filesystem_type&gt;\n    &lt;size&gt; APPSIZE &lt;/size&gt;\n    &lt;file_system_attribute&gt; 0 &lt;/file_system_attribute&gt;\n    &lt;allocation_attribute&gt; 0x808 &lt;/allocation_attribute&gt;\n    &lt;align_boundary&gt; 16384 &lt;/align_boundary&gt;\n    &lt;percent_reserved&gt; 0 &lt;/percent_reserved&gt;\n    &lt;unique_guid&gt; APPUUID &lt;/unique_guid&gt;\n    &lt;filename&gt; APPFILE &lt;/filename&gt;\n    &lt;description&gt; **Required.** Contains the rootfs. This partition must be assigned\n        the \"1\" for id as it is physically put to the end of the device, so that it\n        can be accessed as the fixed known special device `/dev/mmcblk0p1`. &lt;/description&gt;\n&lt;/partition&gt;\n</code></pre> <p>Then connect the target unit to Linux PC, put it into Forced Recovery mode to flash the Jetson with your image.</p> <pre><code>sudo cp gtc-jp5.img bootloader/system.img\nsudo ADDITIONAL_DTB_OVERLAY=\"BootOrderEmmc.dtbo\" ./flash.sh -r jetson-agx-orin-devkit mmcblk0p1\n</code></pre>"},{"location":"setup_jetson.html#jetson-misc-setup","title":"Jetson misc setup","text":""},{"location":"setup_jetson.html#stop-auto-screen-blanking","title":"Stop auto screen blanking","text":"<pre><code>gsettings set org.gnome.desktop.session idle-delay 0\n</code></pre> <p>After that you can double-check on GUI by going \"Settings\" &gt; \"Power\" &gt; \"Power Saving Options\" to check \"Screen Black\" to have been set to \"Never\".</p>"},{"location":"setup_lab.html","title":"Lab Setup","text":"<p>This page documents how things are set up / prepared prior to the course by instructors and stuff.</p>"},{"location":"setup_lab.html#site-setup","title":"Site setup","text":""},{"location":"setup_lab.html#lab-room-setup","title":"Lab room setup","text":""},{"location":"setup_lab.html#table-setup","title":"Table setup","text":""},{"location":"setup_pc.html","title":"Linux PC setup","text":""},{"location":"setup_pc.html#ubuntu-setup","title":"Ubuntu setup","text":"<ul> <li>Install Ubuntu 22.04</li> </ul>"},{"location":"setup_pc.html#install-nvidia-driver","title":"Install NVIDIA driver","text":"<p> Official Isaac ROS Documentation - Isaac Sim Driver Requirements</p> <pre><code>sudo apt-get install nvidia-driver-525\n</code></pre>"},{"location":"setup_pc.html#isaac-sim-setup","title":"Isaac Sim setup","text":""},{"location":"setup_pc.html#install-omniverse-launcher","title":"Install Omniverse Launcher","text":"<p>Download Omniverse Launcher</p> <ul> <li>Link for Linux</li> </ul> <p>Install Omnivese Launcher</p> <pre><code>sudo apt install libfuse2\nchmod +x ./omniverse-launcher-linux.AppImage\n./omniverse-launcher-linux.AppImage\n</code></pre>"},{"location":"setup_pc.html#install-isaac-sim","title":"Install Isaac Sim","text":"<p> Official Isaac ROS Documentation - Workstation Installation</p> <p></p> <p>Install Release 2023.1.1.</p> <p></p>"},{"location":"setup_pc.html#foxglove-setup","title":"Foxglove setup","text":""},{"location":"setup_pc.html#install-foxglove","title":"Install Foxglove","text":"<p>Download and install.</p> <pre><code>wget https://get.foxglove.dev/desktop/latest/foxglove-studio-1.87.0-linux-amd64.deb\nsudo apt install ./foxglove-studio-*.deb\n</code></pre> <p>Install the ROS bridge</p> <pre><code>source /opt/ros/\nsudo apt install ros-$ROS_DISTRO-foxglove-bridge\n</code></pre>"},{"location":"setup_pc.html#save-pre-made-layout-config-locally","title":"Save pre-made layout config locally","text":"<p>Start the Foxglove Bridge</p> <pre><code>ros2 launch foxglove_bridge foxglove_bridge_launch.xml\n</code></pre> <p>Then start the Foxglove Studio from GUI or CUI.</p> <pre><code>foxglove-studio\n</code></pre> <p>Click on \"Open connection\"</p> <p></p> <p>Select \"Foxglove WebSocket\", leave the WebSocket URL as <code>ws://localhost:8765</code> and click on \"Open\".</p> <p></p> <p>For viewing the camera images published, and controlling the robot by publishing <code>/cmd_vel</code> messages, you can setup a layout like this to enable \"FPV tele-operation\".</p> <p></p> <p>Save the layout config to a local file for use later. Click the Foxglove icon at the top left corner, select View &gt; Export layout to file ....</p> <p></p> <p>Name it <code>foxglove_fpv_layout.json</code> or something appropriate and save it under the home directory.</p>"},{"location":"isaac-sim/index.html","title":"Hands-on Session on Isaac Sim","text":""},{"location":"isaac-sim/index.html#about-isaac-sim","title":"About Isaac Sim","text":"<p> Official Isaac Sim Documentation - Link</p> <p>NVIDIA Omniverse\u2122 Isaac Sim is a robotics simulation toolkit on the NVIDIA Omniverse\u2122 platform, offering tools for creating virtual robotic environments and experiments. It supports navigation, manipulation via ROS/ROS2, and simulates sensor data like RGB-D, Lidar, and IMU for computer vision applications, including domain randomization and ground-truth labeling.</p> <p>Note</p> <p>Through out the following exercises, you may see this warning dialog when you open our pre-scripted USD file. You can just press \"Yes\" to dismiss.</p> <p></p> <p>Also, when you close the USD file, press \"Don't Save\" so that you get to re-use the provided USD files in the way later.</p> <p></p>"},{"location":"isaac-sim/index.html#exercise-composition","title":"Exercise composition","text":"<p>Hands-on session on Isaac Sim is composed of 5 exercises.</p> <p>Some exercises are designed to be built upon the result of previous exercise. However we provide a pre-configured USD file at each exercise completion, so you can skip some exercise.</p>"},{"location":"isaac-sim/index.html#exercise-11-launch-isaac-sim-hands-on","title":"Exercise 1.1 Launch Isaac Sim [Hands-on]","text":"<p>We introduce two ways to launch Isaac Sim.</p> <p> Go to the exercise </p>"},{"location":"isaac-sim/index.html#exercise-12-create-an-environment-in-isaac-sim-hands-on","title":"Exercise 1.2 Create an Environment in Isaac Sim [Hands-on]","text":"<p>We learn how we can build an environment from scratch using primitives in Isaac Sim as well as using pre-created assets. </p> <p> Go to the exercise </p>"},{"location":"isaac-sim/index.html#exercise-13-load-assets-in-isaac-sim","title":"Exercise 1.3 Load Assets in Isaac Sim.","text":"<p>We will learn</p> <ul> <li>How to add props/assets, place and move them, and view the environment from desired perspectives [Hands-on]</li> <li>How to add people in an environment using <code>omni.anim.people</code> extension</li> <li>How to add a robot in the scene using the URDF file</li> <li>How to attach a camera to the robot</li> </ul> <p> Go to the exercise </p>"},{"location":"isaac-sim/index.html#exercise-14-action-graph-to-drive-a-robot-hands-on","title":"Exercise 1.4 Action Graph to drive a robot [Hands-on]","text":"<p>We will learn how to construct an Action Graph for driving a robot in the simulator from ROS 2 side.</p> <p> Go to the exercise </p>"},{"location":"isaac-sim/index.html#exercise-15-action-graph-for-robot-camera-hands-on","title":"Exercise 1.5 Action Graph for robot camera [Hands-on]","text":"<p>We will learn how to construct an Action Graph for publishing robot camera images to ROS 2 side.</p> <p> Go to the exercise </p>"},{"location":"isaac-sim/isaac-sim_01.html","title":"Exercise 1.1 Launch Isaac Sim","text":"<p> Documentation - Link</p> <p>Info</p> GUITerminal (CUI) <ol> <li>Open Omniverse Launcher</li> <li>Navigate to the LIBRARY tab, choose Isaac Sim from the sidebar, and click Launch to open Isaac Sim App Selector.     </li> <li>Click START to run the Isaac Sim main app.     </li> </ol> <ol> <li>Open a terminal ( Ctrl+Alt+T )</li> <li> <p>Type the following and hit Enter.</p> <pre><code>~/.local/share/ov/pkg/isaac_sim-2023.1.1/isaac-sim.sh -v\n</code></pre> </li> </ol> <p>Next</p>"},{"location":"isaac-sim/isaac-sim_01.html#pc-setup-before-the-lab","title":"PC setup before the lab","text":"<p>Please check \"PC setup\" page to check how the Linux PC is set up prior to the course offering. </p>"},{"location":"isaac-sim/isaac-sim_02.html","title":"Exercise 1.2 Create an Environment in Isaac Sim","text":"<p> Documentation - Link</p> With a simple plane groundWith Isaac Sim Assets <p>Info</p> <p>If you find yourself lost in the stage, just click on an item in the Stage tab, a press F to focus on it.</p> <p></p>"},{"location":"isaac-sim/isaac-sim_02.html#create-an-environment-with-a-simple-plane-ground","title":"Create an environment with a simple plane ground","text":"<ol> <li>Select \"Create\" in the Menu Bar, then choose \"Physics\" &gt; \"Physics Scene\" to add it to the stage tree. Check its properties to see gravity set at <code>-Z</code> with a magnitude of 9.8</li> <li>Click \"Create\" in the Menu Bar, then choose \"Physics\" &gt; \"Ground Plane.\"</li> <li>Click \"Create\" in the Menu Bar, then select \"Shapes\" &gt; \"Cube.\"</li> <li>Select the Cube, then in the Property tab, click the + Add button and choose \"Physics\" &gt; \"Rigid Body\" with Colliders Preset.</li> </ol> <p>Tip</p> <p>How to navigate in the Viewport</p> <ul> <li>Mouse Right-click and drag to tilt/pan</li> <li>Mouse Right-click and W A S D to move forward/left/back/right, Q E to move up/down</li> <li>Copy an object position by going to \"Transform\" tab</li> </ul> <p>Next</p>"},{"location":"isaac-sim/isaac-sim_02.html#create-an-environment-with-isaac-sim-assets","title":"Create an environment with Isaac Sim Assets","text":"<p>Prepare asset packs for course</p> <p>Unzip the asset packs prepared for this course and save it under Desktop.</p> <pre><code>cd ${HOME}\nls -lh Isaac_ROS_Isaac_SIM_\\[DLIT61534\\].zip\nunzip Isaac_ROS_Isaac_SIM_\\[DLIT61534\\].zip -d ${HOME}/Desktop\nexport COURSE_DIR=/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_\\[DLIT61534\\]\n</code></pre> <ol> <li>Go to the Content tab in Isaac Sim</li> <li>Navigate to <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/</code></li> <li> <p>Select the environment you want to work in.In our case we will be working with <code>Simple_Warehouse/warehouse.usd</code></p> <p>Tip</p> <p>We will be accessing this <code>Simple_warehouse</code> directory often through out this course, so it's a good idea to Add Bookmark this directory.</p> <p></p> <p>Once you do this, you can easily access from the Bookmarks.</p> <p></p> </li> </ol> <p>An environment set up like this should appear.</p> <p></p> <p>Tip</p> <p>How to navigate in the Viewport</p> <ul> <li>Mouse Right-click and drag to tilt/pan</li> <li>Mouse Right-click and W A S D to move forward/left/back/right, Q E to move up/down</li> <li>Copy an object position by going to \"Transform\" tab</li> </ul> <p>Next</p>"},{"location":"isaac-sim/isaac-sim_03.html","title":"Exercise 1.3 Load Assets in Isaac Sim","text":"<p> Documentation - Link</p> <p>Prepare asset packs for course</p> <p>Unzip the asset packs prepared for this course and save it under Desktop.</p> <pre><code>cd ${HOME}\nls -lh Isaac_ROS_Isaac_SIM_\\[DLIT61534\\].zip\nunzip Isaac_ROS_Isaac_SIM_\\[DLIT61534\\].zip -d ${HOME}/Desktop\nexport COURSE_DIR=/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_\\[DLIT61534\\]\n</code></pre> <p>Later in this document, we will refer this \"<code>Isaac_ROS_Isaac_SIM_[DLIT61534]</code>\" directory under Desktop as <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]</code>.</p>"},{"location":"isaac-sim/isaac-sim_03.html#13a-add-propsassets","title":"1.3a. Add Props/Assets","text":"<ol> <li>Go to the Content tab in Isaac Sim</li> <li> <p>Go to <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Props/</code></p> Asset Location Asset Class <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Props/</code> Warehouse Essentials: (Factory, Forklift, Pallet, Dolly...) <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Commercial 3D Models Pack/Assets/ArchVis/Commercial/</code> Commercial Assets: (Chair, Table, Racks, Sofa...) <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 3/Assets/Isaac/2023.1.1/NVIDIA/Assets/ArchVis/Residential/</code> Residential Necessities: (Kitchen Items, Furniture, Food...) </li> <li> <p>Drag and drop the assets into the scene</p> <p></p> <p>Tip</p> <p>How to navigate in the Viewport</p> <ul> <li>Mouse Right-click and drag to tilt/pan</li> <li>Mouse Right-click and W A S D to move forward/left/back/right, Q E to move up/down</li> <li>Copy an object position by going to \"Transform\" tab</li> </ul> </li> <li> <p>Select the assets, then in the Property tab, click the + Add button and choose Physics &gt; Rigid Body with Colliders Preset</p> </li> </ol> <p>How to move the Asset</p> <p>If you want to move the asset around, always select the asset from the stage and then use the arrows shown on the viewport to move the asset in X,Y or Z direction</p> <p></p> <p>Info</p> <p>If you plan to continue working on the later exercise using the environment you have been working on, save the environment file by selecting File &gt; Save As... or Ctrl+Shift+S. </p> <p></p> Cheat-file (course_env_1.usd) <p>You can access a pre-populated environment at <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/Simple_Warehouse/course_env_1.usd</code></p> <p></p>"},{"location":"isaac-sim/isaac-sim_03.html#13b-add-people","title":"1.3b. Add People","text":"<p> Documentation - Link</p> <p>Cheat-file (course_env_2.usd)</p> <p>You can access a pre-populated environment at <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/Simple_Warehouse/course_env_2.usd</code></p> <p></p> <p>Note</p> <p>When you open these cheat environment files, a pop up window may show up. Press \"Yes\".</p> <p></p> <ol> <li> <p>Load the environment needed for the simulation.    Make sure the parent prim /World exists, if not create the prim /World.</p> <p>Info</p> <p>For the GTC lab, you can load the cheat-file below, <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/Simple_Warehouse/course_env_2.usd</code>.</p> </li> <li> <p>Open the extension manager via Window &gt; Extensions. Search for \"people\" and enable the omni.anim.people extension.</p> <p></p> <p>Tip</p> <p>Check \"AUTOLOAD\" to enable this extension by default. It will come handy when you need to restart Isaac Sim frequently.</p> </li> <li> <p>Load the People Simulation UI by navigating to Window &gt; People Simulation.</p> <p></p> </li> <li> <p>Copy this text in the Command Text Box. [Place the people in according to your environment] </p> <pre><code>Spawn Tom -6 0 0 0\nSpawn Jerry 3 10 0 0\nTom GoTo -6 12 0 _\nJerry GoTo 3 -3 0 _\n</code></pre> </li> <li> <p>Click the Load Characters button to load the characters assets and animations </p> </li> <li> <p>Next, click on the Setup Characters button to attach Behavior Scripts and Animation Graph to the characters.</p> <p></p> <p>Note</p> <p>If you get a login screen on a course supplied PC, then add the following credentials:</p> <ul> <li>Username : <code>admin</code></li> <li>Password : <code>admin</code></li> </ul> <p></p> <p>In case parent prim World does not exist</p> <ol> <li>In the Stage tab, Right-click the Root prim and choose \"Clear Default Prim.\"</li> </ol> <p></p> <ol> <li>In the Stage tab, Right-click and select Create &gt; Xform.</li> </ol> <p></p> <ol> <li>In the Stage tab, rename Xform to World by double-clicking it and editing the name.</li> </ol> <p></p> <ol> <li>In the Stage tab, rename Root prim to Warehouse by double-clicking it and editing the name.</li> </ol> <p></p> <ol> <li>Drag the Warehouse prim into the World prim.</li> </ol> <p></p> <ol> <li>Right-click the World prim and select \"Set as Default Prim.\"</li> </ol> <p></p> </li> <li> <p>Next, turn off the Navmesh Based Navigation setting and click Play to run the simulation.</p> <p></p> <p>Note</p> <p>To further customize the people simulation, explore this link.</p> </li> </ol> <p>Info</p> <p>If you plan to continue working on the later exercise using the environment you have been working on, save the environment file by selecting File &gt; Save As... or Ctrl+Shift+S. </p>"},{"location":"isaac-sim/isaac-sim_03.html#13c-add-a-robot","title":"1.3c. Add a Robot","text":"<p>Info</p> <p>On the course supplied PC, we've already cloned the Turtlebot description package using the following command:</p> <pre><code>cd /home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]\ngit clone -b humble-devel https://github.com/ROBOTIS-GIT/turtlebot3.git turtlebot3\n</code></pre> <ol> <li> <p>Open the URDF importer Isaac Utils &gt; Workflows &gt; URDF Importer.</p> <p></p> </li> <li> <p>In the prompt window, under Import Options, make sure \"Clear Stage\" is deselected to keep the current environment, uncheck \"Fix Base Link\" for mobility, and switch \"Joint Drive Type\" to Velocity.</p> <p></p> </li> <li> <p>In the Import section, select the URDF file in the Input File and Output File. </p> <ul> <li> <p>Input File location of the URDF file for turtlebot:</p> <p><code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/turtlebot3/turtlebot3_description/urdf/turtlebot3_burger.urdf</code></p> </li> <li> <p>Output File location:</p> <p>`/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/</p> </li> </ul> </li> <li> <p>Ensure nothing is selected on the stage by clicking an empty space in the Stage tab or selecting /World in the tree.</p> <p></p> </li> <li> <p>Click Import to proceed and place the robot according to your environment.</p> <p></p> <p>Note</p> <p>You may encounter this confirmation dialog, if you already have the <code>turtlebot3_burger.usd</code> in the output folder mentioned above.</p> <p></p> <p></p> </li> </ol>"},{"location":"isaac-sim/isaac-sim_03.html#13d-attach-a-camera-to-the-robot","title":"1.3d. Attach a camera to the robot","text":"<p>Cheat-file (course_env_3.usd)</p> <p>You can access a pre-populated environment at <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/Simple_Warehouse/course_env_3.usd</code></p> <p></p> <ol> <li> <p>Go to <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Sensors/Intel/RealSense/</code></p> </li> <li> <p>Drag and drop the <code>rsd455.usd</code> in the viewport.</p> <p></p> </li> <li> <p>Drag the rsd455 prim into the <code>/World/turtlebot3_burger/base_scan</code> prim </p> <p></p> </li> <li> <p>Adjust the camera placement according to the robot's position.</p> <p></p> <p>Tip</p> <p>Moving an object to a certain location:</p> <ul> <li>Copy an object position by going to \"Transform\" tab</li> </ul> </li> <li> <p>Change the Viewport camera to Realsense by selecting the Camera icon on the viewport, then navigating to Camera -&gt; Camera_OmniVision_OV9782_Color.</p> <p></p> </li> </ol> <p>Info</p> <p>If you plan to continue working on the later exercise using the environment you have been working on, save the environment file by selecting File &gt; Save As... or Ctrl+Shift+S. </p> <p>Next</p>"},{"location":"isaac-sim/isaac-sim_04.html","title":"Exercise 1.4 Build Action Graph to drive a robot","text":"<p> Documentation - Link</p> <p>Cheat-file (course_env_4.usd)</p> <p>You can access a pre-populated environment at <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/Simple_Warehouse/course_env_4.usd</code></p> <p></p> <p>Tip</p> <p>How to navigate in the Visual Scripting graph editor:</p> <ul> <li>Middle Mouse Button and drag to pan the editor view left, right, up, and down</li> <li>Mouse Wheel to zoom toward or away from nodes in the editor</li> </ul>"},{"location":"isaac-sim/isaac-sim_04.html#omnigraph","title":"OmniGraph","text":"<p> Documentation - Link</p> <p>OmniGraph is Omniverse's visual programming tool, enabling easy function integration from various systems and supporting custom nodes for personalized functionality, leveraging Omniverse's efficient computation. In Omniverse Isaac Sim, it powers Replicators, ROS bridges, sensor integration, and more, serving as a crucial component. This tutorial offers a quick introduction to OmniGraph, with a recommendation to explore the detailed documentation for a comprehensive understanding.  </p>"},{"location":"isaac-sim/isaac-sim_04.html#step-1-open-visual-scripting","title":"Step 1. Open Visual Scripting","text":"<p>Go to Window &gt; Visual Scripting &gt; Action Graph.</p> <p></p>"},{"location":"isaac-sim/isaac-sim_04.html#step-2-create-new-action-graph","title":"Step 2. Create new Action Graph","text":"<p>Click on the New Action Graph icon in the middle of the Action Graph window.</p> <p></p>"},{"location":"isaac-sim/isaac-sim_04.html#step-3-build-graph","title":"Step 3. Build graph","text":"<p>Search the relevant nodes in the search bar and build the graph shown below.</p> <p></p>"},{"location":"isaac-sim/isaac-sim_04.html#action-graph-nodes","title":"Action Graph nodes","text":"<ul> <li>On Playback Tick Node: Generates a tick during simulation playback, ensuring nodes execute their functions every simulation step.</li> <li>ROS2 Context Node: Establishes a context with a specified Domain ID for ROS2 communication. It can import the ROS_DOMAIN_ID from the environment if enabled.</li> <li>ROS2 Subscribe Twist Node: Subscribes to Twist messages, typically used for controlling robotic motion. It triggers the Differential Node to calculate differential commands when a new Twist message is received.</li> <li>Break 3-Vector Node: Decomposes 3-dimensional vectors (such as linear and angular velocities from Twist messages) into individual components before feeding them into the Differential Controller node.<ul> <li>Twist message type</li> </ul> </li> <li>Differential Controller Node: Receives desired vehicle speed and computes wheel speed based on wheel radius, wheel distance, and maximum linear speed parameters. It ensures proper motion control for the robot.</li> <li>Articulation Controller Node: Moves specified joints of the target robot using commands such as Position, Velocity, or Effort commands. It's often configured to control the movement of a robot's joints.</li> <li>Constant Token Node: Constant Token nodes are used to input the names of wheel joints, which are then combined into an array using a Make Array node. This array is used by the Articulation Controller node to control the robot's joints.</li> </ul>"},{"location":"isaac-sim/isaac-sim_04.html#step-4-set-the-node-properties","title":"Step 4. Set the node properties","text":"<ol> <li> <p>[Optional] Assign ROS DOMAIN ID if needed using ROS2 Context Node.</p> <p></p> </li> <li> <p>Specify the topicName (<code>cmd_vel</code>) to publish the ROS twist commands using the ROS2 Subscribe Twist Node.</p> <p></p> </li> <li> <p>Specify the names of the wheel joints inside each of the Constant Token Nodes </p> <p> </p> </li> <li> <p>In the Differential Controller node's property tab, input the wheel radius, wheel distance, and maximum linear speed to match the Turtlebot specifications.</p> <p></p> </li> <li> <p>Assign the Articulation Controller node's target to be the Turtlebot</p> <p></p> </li> </ol> <p>Info</p> <p>If you plan to continue working on the later exercise using the environment you have been working on, save the environment file by selecting File &gt; Save As... or Ctrl+Shift+S. </p>"},{"location":"isaac-sim/isaac-sim_04.html#step-5-play","title":"Step 5. Play","text":"<p>Click \"Play\" icon</p>"},{"location":"isaac-sim/isaac-sim_04.html#step-6-verification","title":"Step 6. Verification","text":"<p>Verify the ActionGraph by controlling the robot from ROS 2 side.</p> <code>teleop_twist_keyboard</code>Foxglove <p>Open a terminal and source ros2 </p> <pre><code>source /opt/ros/humble/setup.bash\n</code></pre> <p>Control the Turtlebot using the keyboard with <code>teleop_twist_keyboard</code> package.</p> <pre><code>ros2 run teleop_twist_keyboard teleop_twist_keyboard\n</code></pre> <p></p> <p></p> <p>Next</p> <ol> <li> <p>Start the Foxglove Bridge</p> <pre><code>ros2 launch foxglove_bridge foxglove_bridge_launch.xml\n</code></pre> </li> <li> <p>Then start the Foxglove Studio from GUI or CUI.</p> <pre><code>foxglove-studio\n</code></pre> </li> <li> <p>Click on \"Open connection\"</p> <p></p> <p>Select \"Foxglove WebSocket\", leave the WebSocket URL as <code>ws://localhost:8765</code> and click on \"Open\".</p> <p></p> </li> <li> <p>Add teleop widget and set the topic to be <code>/cmd_vel</code>.</p> <p> </p> </li> <li> <p>Once Foxglove is ready, on Isaac Sim, hit \"Play\" button.</p> </li> <li> <p>Perform teleop to verify Action Graph for driving robot</p> </li> </ol> <p>Next</p>"},{"location":"isaac-sim/isaac-sim_05.html","title":"Exercise 1.5 Build Action Graph for robot camera","text":"<p> Documentation - Link</p> <p>Cheat-file (course_env_5.usd)</p> <p>You can access a pre-populated environment at <code>/home/nvidia/Desktop/Isaac_ROS_Isaac_SIM_[DLIT61534]/Isaac Sim Assets Pack 1/Assets/Isaac/2023.1.1/Isaac/Environments/Simple_Warehouse/course_env_5.usd</code></p> <p></p>"},{"location":"isaac-sim/isaac-sim_05.html#step-1-open-visual-scripting","title":"Step 1. Open Visual Scripting","text":"<p>Go to Window &gt; Visual Scripting &gt; Action Graph.</p> <p></p>"},{"location":"isaac-sim/isaac-sim_05.html#step-2-create-new-action-graph","title":"Step 2. Create new Action Graph","text":"<p>Click on the New Action Graph icon in the middle of the Action Graph window.</p> <p></p>"},{"location":"isaac-sim/isaac-sim_05.html#step-3-build-graph","title":"Step 3. Build graph","text":"<p>Search the relevant nodes in the search bar and build the graph shown below.</p> <p></p>"},{"location":"isaac-sim/isaac-sim_05.html#action-graph-components","title":"Action Graph components","text":"<ul> <li>On Playback Tick Node: Generates a tick during simulation playback, ensuring nodes execute their functions every simulation step.</li> <li>Constant String: Holds a string constant value</li> <li>Isaac Create Render Product: Isaac Sim node that creates a render product for use with offscreen rendering</li> <li>ROS2 Camera Helper: This node handles automation of the camera sensor pipeline</li> </ul> <p>Note</p> <p>For clarity, you can visually divide the graph into two sections: one for the left camera and the other for the right camera, as depicted in the image below.</p> <p></p>"},{"location":"isaac-sim/isaac-sim_05.html#step-4-set-the-node-properties","title":"Step 4. Set the node properties","text":"<ol> <li> <p>[Optional] Assign ROS DOMAIN ID if needed using ROS2 Context Node.</p> <p></p> </li> <li> <p>Assign the left camera Prim to render camera data in the first Isaac Create Render Product Node.</p> <p></p> <p>Select the target for left camera</p> <p></p> <p>After selecting the target, cameraPrim parameter will be populate with this path for the left camera:</p> <ul> <li><code>/World/turtlebot3_burger/base_scan/rsd455/RSD455/Camera_OmniVision_OV9782_Left</code></li> </ul> </li> <li> <p>Assign the right camera Prim to render camera data in the second Isaac Create Render Product Node.</p> <p></p> <p>Select the target for right camera</p> <p></p> <p>After selecting the target, cameraPrim parameter will be populate with this path for the right camera:</p> <ul> <li><code>/World/turtlebot3_burger/base_scan/rsd455/RSD455/Camera_OmniVision_OV9782_Right</code></li> </ul> <p></p> </li> <li> <p>Set the input value of the first Constant String node as the left camera name - \"Camera_OmniVision_OV9782_Left\"</p> <p></p> </li> <li> <p>Set the input value of the second Constant String node as the right camera name - \"Camera_OmniVision_OV9782_Right\"</p> <p></p> </li> <li> <p>Set the topicName and data type for each ROS2 Camera Helper Node. In this example, we'll utilize two topics (camera_info and rgb) for each camera (left and right), requiring a total of 4 ROS2 Camera Helper Nodes as depicted above.  Set the topics for each ROS2 camera node as follows:</p> node 1node 2node 3node 4 <ul> <li>topicName : <code>/front/stereo_camera/left/camera_info</code></li> <li>type : <code>camera_info</code></li> </ul> <p></p> <ul> <li>topicName : <code>/front/stereo_camera/left/rgb</code></li> <li>type : <code>rgb</code></li> </ul> <p></p> <ul> <li>topicName : <code>/front/stereo_camera/right/camera_info</code></li> <li>type : <code>camera_info</code></li> </ul> <p></p> <ul> <li>topicName : <code>/front/stereo_camera/right/rgb</code></li> <li>type : <code>rgb</code></li> </ul> <p></p> </li> </ol> <p>Info</p> <p>If you plan to continue working on the later exercise using the environment you have been working on, save the environment file by selecting File &gt; Save As... or Ctrl+Shift+S. </p> <p>Tip</p> <p>In case you run into OOM (out of memory) issue, you should try lowering the camera rendering resolution.</p> <p>For each Isaac Create Render Product node,  lower the values for <code>height</code> and <code>width</code> in Inputs pane.</p> <p></p> <p>Make sure to perform this for both nodes, one for the left camera, one for the right camera.</p>"},{"location":"isaac-sim/isaac-sim_05.html#step-5-play","title":"Step 5. Play","text":"<p>Click \"Play\" icon</p>"},{"location":"isaac-sim/isaac-sim_05.html#step-6-verification","title":"Step 6. Verification","text":"<p>Verify the Action Graph by viewing the simulated world through robots cameras using ROS 2.</p> RViz2Foxglove <p>Open a terminal and source ros2 </p> <pre><code>source /opt/ros/humble/setup.bash\n</code></pre> <p>Open RViz2 to visualize the output from the camera</p> <pre><code>rviz2\n</code></pre> <ol> <li> <p>Once the RViz window opens, click on \"Add.\"</p> <p></p> </li> <li> <p>Select \"Image\" and hit \"OK\" to visualize the output</p> <p></p> </li> <li> <p>Choose the appropriate ROS2 topic to display its output on the selected display.In our case it would be <code>/front/stereo_camera/right/rgb</code> or <code>/front/stereo_camera/left/rgb</code></p> <p></p> </li> </ol> <p></p> <p>Next</p> <ol> <li> <p>Start the Foxglove Bridge</p> <pre><code>ros2 launch foxglove_bridge foxglove_bridge_launch.xml\n</code></pre> </li> <li> <p>Then start the Foxglove Studio from GUI or CUI.</p> <pre><code>foxglove-studio\n</code></pre> </li> <li> <p>Click on \"Open connection\"</p> <p></p> <p>Select \"Foxglove WebSocket\", leave the WebSocket URL as <code>ws://localhost:8765</code> and click on \"Open\".</p> <p></p> </li> <li> <p>Layout</p> <p>Import the layout config file we provide, so you have all the widgets needed to control the robot with the camera feeds. Open <code>foxglove_fpv_layout.json</code> in home directory.</p> <p></p> </li> <li> <p>Once Foxglove is ready, on Isaac Sim, hit \"Play\" button.</p> </li> <li> <p>Perform teleop with video feeds to verify both Action Graphs</p> <p>You should be able to control the robot using the teleop widget while viewing the images from robot cameras in Foxglove.</p> </li> </ol> <p> Next</p>"}]}